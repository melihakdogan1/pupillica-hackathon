#!/usr/bin/env python3
"""
Ä°laÃ§ VeritabanÄ± OluÅŸturucu
data/kub ve data/kt klasÃ¶rlerindeki TÃœM PDF'leri iÅŸleyerek anlamsal arama veritabanÄ± oluÅŸturur.
"""

import os
import json
import time
import logging
from pathlib import Path
from typing import List, Dict, Any

import chromadb
from chromadb.utils import embedding_functions
from chromadb.config import Settings
import PyPDF2
import pdfplumber
from tqdm import tqdm

# --- KonfigÃ¼rasyon ---
EMBEDDING_MODEL = "sentence-transformers/all-mpnet-base-v2"
DISTANCE_FUNCTION = "cosine"
DB_PATH = "data/veritabani"
COLLECTION_NAME = "ilac_prospektusleri"

# PDF klasÃ¶rleri
KUB_PATH = "data/kub"
KT_PATH = "data/kt"

# Metin parÃ§alama ayarlarÄ±
CHUNK_SIZE = 1000  # Karakter sayÄ±sÄ±
CHUNK_OVERLAP = 200  # Ã–rtÃ¼ÅŸme

# --- Logging Setup ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('veritabani_olusturma.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def extract_text_from_pdf(pdf_path: str) -> str:
    """PDF'den metin Ã§Ä±karÄ±r."""
    text = ""
    
    # Ã–nce pdfplumber ile deneyelim
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
        
        if text.strip():
            return text.strip()
    except Exception as e:
        logger.warning(f"pdfplumber ile okuma baÅŸarÄ±sÄ±z {pdf_path}: {e}")
    
    # pdfplumber baÅŸarÄ±sÄ±zsa PyPDF2 ile deneyelim
    try:
        with open(pdf_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            for page in pdf_reader.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
        
        return text.strip()
    except Exception as e:
        logger.error(f"PDF okuma baÅŸarÄ±sÄ±z {pdf_path}: {e}")
        return ""

def chunk_text(text: str, chunk_size: int = CHUNK_SIZE, overlap: int = CHUNK_OVERLAP) -> List[str]:
    """Metni Ã¶rtÃ¼ÅŸen parÃ§alara bÃ¶ler."""
    if len(text) <= chunk_size:
        return [text]
    
    chunks = []
    start = 0
    
    while start < len(text):
        end = start + chunk_size
        
        # Kelime sÄ±nÄ±rlarÄ±nda kesmeye Ã§alÄ±ÅŸ
        if end < len(text):
            # Geriye doÄŸru en yakÄ±n boÅŸluÄŸu bul
            while end > start and text[end] not in [' ', '\n', '.', '!', '?']:
                end -= 1
            
            if end == start:  # BoÅŸluk bulunamadÄ±ysa orijinal konumu kullan
                end = start + chunk_size
        
        chunk = text[start:end].strip()
        if chunk:
            chunks.append(chunk)
        
        start = end - overlap
        if start >= len(text):
            break
    
    return chunks

def find_all_pdfs() -> List[Dict[str, str]]:
    """KUB ve KT klasÃ¶rlerindeki tÃ¼m PDF'leri bulur."""
    pdfs = []
    
    # KUB PDF'leri
    if os.path.exists(KUB_PATH):
        for pdf_file in Path(KUB_PATH).glob("*.pdf"):
            pdfs.append({
                "path": str(pdf_file),
                "type": "KUB",
                "name": pdf_file.stem
            })
    
    # KT PDF'leri
    if os.path.exists(KT_PATH):
        for pdf_file in Path(KT_PATH).glob("*.pdf"):
            pdfs.append({
                "path": str(pdf_file),
                "type": "KT", 
                "name": pdf_file.stem
            })
    
    return pdfs

def create_database():
    """Ana veritabanÄ± oluÅŸturma fonksiyonu."""
    logger.info("Ä°laÃ§ VeritabanÄ± OluÅŸturma BaÅŸlÄ±yor...")
    start_time = time.time()
    
    # --- 1. Embedding Fonksiyonunu YÃ¼kle ---
    logger.info(f"{EMBEDDING_MODEL} modeli yÃ¼kleniyor...")
    try:
        sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(
            model_name=EMBEDDING_MODEL,
            device="cpu"
        )
        logger.info("Embedding modeli baÅŸarÄ±yla yÃ¼klendi.")
    except Exception as e:
        logger.error(f"Embedding modeli yÃ¼klenemedi: {e}")
        return False
    
    # --- 2. ChromaDB Ä°stemcisini BaÅŸlat ---
    os.makedirs(DB_PATH, exist_ok=True)
    client = chromadb.PersistentClient(
        path=DB_PATH,
        settings=Settings(allow_reset=True, anonymized_telemetry=False)
    )
    
    # Eski koleksiyonu sil ve yenisini oluÅŸtur
    try:
        client.delete_collection(name=COLLECTION_NAME)
        logger.info("Eski koleksiyon silindi.")
    except:
        pass
    
    collection = client.create_collection(
        name=COLLECTION_NAME,
        metadata={"hnsw:space": DISTANCE_FUNCTION},
        embedding_function=sentence_transformer_ef
    )
    logger.info(f"'{COLLECTION_NAME}' koleksiyonu '{DISTANCE_FUNCTION}' mesafe fonksiyonu ile oluÅŸturuldu.")
    
    # --- 3. PDF'leri Bul ---
    pdf_files = find_all_pdfs()
    logger.info(f"Toplam {len(pdf_files)} PDF dosyasÄ± bulundu.")
    
    if not pdf_files:
        logger.error("âŒ HiÃ§ PDF dosyasÄ± bulunamadÄ±!")
        return False
    
    # --- 4. PDF'leri Ä°ÅŸle ---
    total_chunks = 0
    batch_size = 50  # Bellek kullanÄ±mÄ±nÄ± kontrol etmek iÃ§in
    batch_docs = []
    batch_ids = []
    batch_metadatas = []
    
    for i, pdf_info in enumerate(tqdm(pdf_files, desc="PDF'ler iÅŸleniyor")):
        pdf_path = pdf_info["path"]
        pdf_type = pdf_info["type"]
        pdf_name = pdf_info["name"]
        
        # PDF'den metin Ã§Ä±kar
        text = extract_text_from_pdf(pdf_path)
        
        if not text or len(text) < 100:
            logger.warning(f"BoÅŸ veya Ã§ok kÄ±sa metin: {pdf_name}")
            continue
        
        # Metni parÃ§alara bÃ¶l
        chunks = chunk_text(text)
        
        for j, chunk in enumerate(chunks):
            if len(chunk) < 50:  # Ã‡ok kÄ±sa parÃ§alarÄ± atla
                continue
            
            doc_id = f"{pdf_type}_{pdf_name}_{j}"
            
            batch_docs.append(chunk)
            batch_ids.append(doc_id)
            batch_metadatas.append({
                "pdf_name": pdf_name,
                "pdf_type": pdf_type,
                "chunk_index": j,
                "chunk_length": len(chunk),
                "source_path": pdf_path
            })
            
            total_chunks += 1
        
        # Belirli aralÄ±klarla veritabanÄ±na ekle
        if len(batch_docs) >= batch_size:
            try:
                collection.add(
                    documents=batch_docs,
                    ids=batch_ids,
                    metadatas=batch_metadatas
                )
                logger.info(f"{len(batch_docs)} parÃ§a veritabanÄ±na eklendi. (Toplam: {total_chunks})")
                
                # Batch'i temizle
                batch_docs = []
                batch_ids = []
                batch_metadatas = []
                
            except Exception as e:
                logger.error(f"âŒ Batch ekleme hatasÄ±: {e}")
                return False
    
    # Kalan parÃ§alarÄ± ekle
    if batch_docs:
        try:
            collection.add(
                documents=batch_docs,
                ids=batch_ids,
                metadatas=batch_metadatas
            )
            logger.info(f"âœ… Son {len(batch_docs)} parÃ§a eklendi.")
        except Exception as e:
            logger.error(f"âŒ Son batch ekleme hatasÄ±: {e}")
            return False
    
    # --- 5. SonuÃ§larÄ± DoÄŸrula ---
    final_count = collection.count()
    duration = time.time() - start_time
    
    logger.info(f"ğŸ“Š VeritabanÄ± oluÅŸturma tamamlandÄ±!")
    logger.info(f"ğŸ“ˆ Ä°ÅŸlenen PDF sayÄ±sÄ±: {len(pdf_files)}")
    logger.info(f"ğŸ“ˆ Toplam metin parÃ§asÄ±: {final_count}")
    logger.info(f"â±ï¸ SÃ¼re: {duration:.2f} saniye")
    
    # Test sorgusu
    if final_count > 0:
        logger.info("ğŸ” Test sorgusu yapÄ±lÄ±yor...")
        test_results = collection.query(
            query_texts=["parol"],
            n_results=3,
            include=['documents', 'distances', 'metadatas']
        )
        
        if test_results and test_results['documents'][0]:
            logger.info("âœ… Test sorgusu baÅŸarÄ±lÄ±!")
            for i, (doc, dist, meta) in enumerate(zip(
                test_results['documents'][0],
                test_results['distances'][0], 
                test_results['metadatas'][0]
            )):
                similarity = 1 - dist
                logger.info(f"   {i+1}. Benzerlik: {similarity:.3f} | PDF: {meta['pdf_name']} | Tip: {meta['pdf_type']}")
                logger.info(f"      Metin: {doc[:100]}...")
        else:
            logger.warning("âš ï¸ Test sorgusu sonuÃ§ vermedi.")
    
    return True

if __name__ == "__main__":
    success = create_database()
    if success:
        logger.info("ğŸ‰ Ä°laÃ§ veritabanÄ± baÅŸarÄ±yla oluÅŸturuldu!")
    else:
        logger.error("âŒ VeritabanÄ± oluÅŸturma baÅŸarÄ±sÄ±z!")